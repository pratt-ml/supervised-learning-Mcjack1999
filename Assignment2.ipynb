{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f98a0-1b6a-42a6-afa0-c1a7ef28b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bc0b7-05f3-426b-a20c-99941821d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c005b5f0-b5fe-4100-b64c-e0abf7bc54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "wine_quality = fetch_ucirepo(id=186) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X_df = wine_quality.data.features \n",
    "y_df = wine_quality.data.targets \n",
    "  \n",
    "# metadata \n",
    "#print(wine_quality.metadata) \n",
    "  \n",
    "# variable information \n",
    "#print(wine_quality.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318614ae-a20e-4092-be86-cca854df60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985d6a0-b432-4c19-ab25-b25b9dc43b0f",
   "metadata": {},
   "source": [
    "Starting the exploratory data analysis. To perform standard pandas operations, I need to convert X and y (which are the features and targets of the dataset, respectively) into pandas DataFrames. I plan to check columns to understand datatypes, value ranges, find possible missing values, the correlation between features, and create relevant data visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e038d4-5e65-4b89-8e86-6db4656dfc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "winedf = pd.concat([X_df, y_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4074c41-2efb-437f-a306-16a2e6fecb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#winedf.head()\n",
    "\n",
    "#winedf.columns\n",
    "\n",
    "#winedf.isnull().sum()\n",
    "\n",
    "#winedf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b391912-e9c1-41da-8aa3-0b0ee66d6e85",
   "metadata": {},
   "source": [
    "#Great no null values! So I dont have to worry about dropping any rows and my chances of missing data or data that was inputted wrong is lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb72d1e5-ce9c-4d95-9d8b-52bf5decf572",
   "metadata": {},
   "source": [
    "#These data types seem to be correct considering most of htem are percentages in decimal form float64 for would be the best Dtype for them. I also see the quality is int64 I beleive this column is the quality ratings given to each wine which would be whole numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78fab48-ea43-4000-aeca-e51848e87125",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_quality.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be193195-b45a-4f4b-a19a-f1f0cbacabce",
   "metadata": {},
   "source": [
    "I was having trouble finding the color column with the code given by the UCI to call the data into python. I believe they made a new datasheet to remove the color column. However, for our assignment I have to hot code a catergorical variable and color is the only catergorical column. After running \"wine_quality.data\" I was able to find the column under \"original\" so my next step it to pull out the orginal datset and work on that moving forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed400f-6827-4429-b0a7-8ec5c0547ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = wine_quality.data['original']\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189609c5-37d2-4f34-9706-2fc72818fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079905a1-e703-40d7-a8bf-624130c0910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time for wine colored graphs\n",
    "\n",
    "plt.scatter(original_data['quality'], original_data['pH'], color = 'maroon')\n",
    "plt.title('relation of pH with wine')\n",
    "plt.xlabel('quality')\n",
    "plt.ylabel('pH')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d62c6a-e85b-40b2-a5b2-78824a102c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Fixed Acidity vs Quality')\n",
    "plt.xlabel('Fixed Acidity')\n",
    "plt.ylabel('Quality')\n",
    "plt.scatter(original_data['fixed_acidity'], original_data['quality'], color = 'magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024a012-35d2-4775-bf7a-8a0d39e7a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(original_data['quality'], original_data['alcohol'], color = 'pink')\n",
    "plt.title('relation of alcohol to wine')\n",
    "plt.xlabel('quality')\n",
    "plt.ylabel('alcohol')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f2016-ae54-4681-a03e-86162aa2ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16b2bb-0f65-49ff-9ab0-d096740d151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting data in two like above\n",
    "\n",
    "X = original_data.drop(columns=['quality'])  # Features\n",
    "y = original_data['quality']\n",
    "\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e49941-c01b-492b-902c-8ce96498b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee77aae-0500-4885-8c7a-8b678638665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,6))\n",
    "sns.barplot(X, palette = 'Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e41aadc-71a7-4203-b636-07f7d91c5e77",
   "metadata": {},
   "source": [
    "Ran into a ValueError when trying to create a correlation matrix so I am going to bring back the features list from the updated dataset because that does not include the color and target(quality) columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be684e7-eb5d-470a-9b17-b2d098155237",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = winedf.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce89bbb-56cd-4aea-beea-99b8033a7cb2",
   "metadata": {},
   "source": [
    "The corrrelation matrix is great to know when proceeding but i belive I will be able to absorb the information better if visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ff760-6b12-4d11-957d-c3a1bcfdfeff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d5d0a-d29d-4ad0-90b3-40e55a0ebc58",
   "metadata": {},
   "source": [
    "From the correlation matrix and plot we can see which features have strong correlation and which features do not. I belive this will be inportant in the future when determining which columns are the most revelant. The alcohol content of the wine has a high correlation with the wine quality. This is important to note because wine quality is what we will working closely with. Some features have negative correlation like density. I plan to remove the features with the most correlation to quality to eliminate some noise if I need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a01b8-888f-4e9e-b050-ee93bead6d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(original_data, hue='color')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796db6b6-9e87-4f30-b94f-e9d408da5b5e",
   "metadata": {},
   "source": [
    "Prediction: I'm not seeing any strong linear relationships in my exploratory graphs. That the random forest will have higher accuracy and F1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d630d13-69ff-41bb-a893-17efa4fd8945",
   "metadata": {},
   "source": [
    "Okay now that I have done all of my exploratory analysis I feel confident to move on to the next step. During my exploratory analysis I did not find any missing values, I know the dtypes of all my columns, and I was able to see the correlation beetween categories. Next I will create a sklearn pipeline that includes preprocessing steps such as scaling and one hot encoding of categorical variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35371231-b797-4e10-a6bd-d0c723e95544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2562a86-5fc7-4731-9cb4-aa4da4f082ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e601bb-acc0-44d1-a248-aae9ce7e1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8903f-561c-42d1-b5a6-8d2c692a40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf440b-4143-4c30-83e3-e1e97c0a3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar',\n",
    "       'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']\n",
    "cat_cols = ['color']\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),  # Scale numerical features\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)  # One-hot encode categorical features\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce16b7d9-93fa-48f5-aac2-ee7263d1d4cf",
   "metadata": {},
   "source": [
    "The first model I will train will be Logicregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cdcc3b-8bf6-495a-a2e6-d552ac5e2232",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor), ('model', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137052ef-4b08-4598-8937-d42ec55891a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# calculating the training and testing accuracies\n",
    "print(\"Training accuracy :\", pipe.score(x_train, y_train))\n",
    "print(\"Testing accuracy :\", pipe.score(x_test, y_test))\n",
    "\n",
    "y_pred = pipe.predict(x_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a885351a-09df-4e5d-b140-8d62e84ba222",
   "metadata": {},
   "source": [
    "From the results of the test above I'm going to proceed with removing some column/features to reduce noise and hopefully help with the overfitting of the model above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a0785-1021-4d96-bda9-29c09c569f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861e4bb-3663-40c6-ab3e-b474c6f4c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsdrop = ['fixed_acidity','residual_sugar', 'total_sulfur_dioxide', 'pH', 'sulphates']\n",
    "X_df = X.drop(columns=columnsdrop)\n",
    "\n",
    "#redoing the test/train split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_df, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34568553-b636-4a7b-97a6-dc6b0c3ff977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_cols1 = ['volatile_acidity', 'citric_acid',\n",
    "      # 'chlorides', 'free_sulfur_dioxide', 'density','alcohol']\n",
    "#cat_cols = ['color']\n",
    "\n",
    "#preprocessor1 = ColumnTransformer(\n",
    "  #  transformers=[\n",
    " #       ('num', StandardScaler(), num_cols1),  # Scale numerical features\n",
    "  #      ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)  # One-hot encode categorical features\n",
    "  #  ])\n",
    "\n",
    "#pipe = Pipeline(steps=[\n",
    " #   ('preprocessor1', preprocessor1), ('model', LogisticRegression())])\n",
    "\n",
    "#pipe.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Training accuracy :\", pipe.score(x_train, y_train))\n",
    "#print(\"Testing accuracy :\", pipe.score(x_test, y_test))\n",
    "#\n",
    "#y_pred = pipe.predict(x_test)\n",
    "\n",
    "#print(\"Classification Report:\")\n",
    "#print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "#print(\"Confusion Matrix:\")\n",
    "#print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83aaa5-5e00-4f28-a49c-4fd5c8bb493e",
   "metadata": {},
   "source": [
    "The results actually seem to be worse. I believe the results are low because the linear relationships between the features and quality are weak as I predicted above. I will comment that attempt out and will move on to randomforest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ff285-3602-40f2-be67-19c4a3ffddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2204e-52fb-405a-a379-6e1cf90e3a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(x_train, y_train)\n",
    "y_pred = pipeline.predict(x_test)\n",
    "\n",
    "# Calculate and print the training and testing accuracies\n",
    "print(\"Training accuracy :\", pipeline.score(x_train, y_train))\n",
    "print(\"Testing accuracy :\", pipeline.score(x_test, y_test))\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8927d-425f-4e89-ade5-9c5e79b810b9",
   "metadata": {},
   "source": [
    "Instantly i can see that these results are a lot better than the logicregression. I'm wondering if the results would be even better excluding some feature so theres less potential for overfitting. To figure out how to make this model a little more accurate I will run a grid search to improve the result. Report the best set of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12eeee6-ab1d-45fc-b431-709988ae2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300, 400],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dcba25-b35f-4803-985f-6c921c17fcba",
   "metadata": {},
   "source": [
    "I wasn't sure which numbers to start off with in the param grid. After doing some research I found that the numbers entered above were \"default\" numbers for when you are unsure what parameters to set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483349c5-92f0-42c4-9eb7-9d78cb64138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipeline, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=5, n_jobs=-1, verbose=2) # Fit the model\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and evaluate\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Cross-validation Score:\", grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87f32d-2ad9-4181-8946-9251b4234502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing accuracy:\", best_model.score(x_test, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f89d2-8a50-4c1a-91f8-ea8a3af43dee",
   "metadata": {},
   "source": [
    "trying again but using RandomizedSearchCV instead to see if i can get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34268dac-20a4-4a67-bbe7-560a0e71db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "param_grid1 = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2', None]  # Removed 'auto'\n",
    "}\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(pipeline, param_distributions=param_grid1, n_iter=100,\n",
    "                            cv=StratifiedKFold(n_splits=3), scoring='f1_weighted',\n",
    "                            random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453c096-7c51-4a20-b0ef-9003e8e92856",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Best parameters found: \", search.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ed02e21-2e0a-4dad-b5d1-c9020c414dde",
   "metadata": {},
   "source": [
    "The best set of parameters for my model is above so I will rerun to see if my model will be slightly better. Because I already included some of the parameter in my first test I believe the results will a hair difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b25afee-e0d7-487a-9e14-15014b07de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = search.best_estimator_\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy = best_model.score(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023efe93-1068-4102-a91f-c76f456f3f29",
   "metadata": {},
   "source": [
    "Next, I will use the best model to create a function that takes a single row of test data and predict the quality of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f8a8be-31e1-41ea-826b-34756a9bbadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine_quality(row, best_model):\n",
    "    result = best_model.predict(row)\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea77cf-f1fc-4edb-870d-de9187114368",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = X.iloc[[16]]\n",
    "\n",
    "predicted_quality = wine_quality(sample_row, best_model)\n",
    "\n",
    "print(f\"Predicted wine quality: {predicted_quality}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ea170-abcc-44d5-a5eb-7441be25d14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
